telemetry:
  logging:
    level: debug  # debug, info, warn, error, fatal
    encoding: console

api:
  http:
    listen_addr: 0.0.0.0:7685 # not supported currently
    max_body_size: "2Mi"
    tls:
      ca_path:
      cert_path:
    # other configs

routers:
  language:
    - id: openai-pool
      strategy: priority # round-robin, weighted-round-robin, priority, least-latency, priority, etc.
      models:
        - id: primary
          openai: # cohere, azureopenai, gemini, other providers we support
            model: gpt-3.5-turbo
            api_key: "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"
            default_params:
              temperature: 0.1

        - id: secondary
          cohere:
            model: command-light
            api_key: "LXeDdTbRN17H4tDFTyP6b2E7LeXMM9oCkm1Fd1ig"
            default_params: # set the default request params
              temperature: 0.1

    - id: latency-critical-pool
      strategy: least_latency
      models:
        - id: primary
          timeout_ms: 200
          openai:
            model: gpt-3.5-turbo
            api_key: ${env:OPENAI_API_KEY}
        
        - id: secondary
          timeout_ms: 200
          cohere:
            api_key: ${env:COHERE_API_KEY}

    - id: cohere-openai-ab-test
      strategy: weighted_round_robin
      models:
        - id: openai
          openai:
            api_key: ${env:OPENAI_API_KEY}
        - id: cohere
          cohere:
            api_key: ${env:COHERE_API_KEY}

