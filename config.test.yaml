telemetry:
  logging:
    level: debug  # debug, info, warn, error, fatal
    encoding: console

api:
  http:
    listen_addr: 0.0.0.0:7685 # not supported currently
    max_body_size: "2Mi"
    tls:
      ca_path:
      cert_path:
    # other configs

routers:
  language:
    - id: openai-pool
      strategy: priority # round-robin, weighted-round-robin, priority, least-latency, priority, etc.
      models:
        - id: primary
          openai: # cohere, azureopenai, gemini, other providers we support
            model: gpt-3.5-turbo
            api_key: ${env:OPENAI_API_KEY}
            default_params:
              temperature: 0.1

        - id: secondary
          cohere:
            model: command-light
            apiKey: ${env:COHERE_API_KEY}
            default_params: # set the default request params
              temperature: 0.1

    - id: openai-fail
      strategy: priority
      models:
        - id: openai
          openai:
            api_key: ${env:OPENAI_API_KEY}
        - id: cohere
          cohere:
            api_key: ${env:COHERE_API_KEY}

